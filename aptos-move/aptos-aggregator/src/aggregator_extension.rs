// Copyright Â© Aptos Foundation
// SPDX-License-Identifier: Apache-2.0

use crate::{
    delta_change_set::{abort_error, addition, subtraction, EADD_OVERFLOW, ESUB_UNDERFLOW},
    resolver::AggregatorResolver,
};
use aptos_table_natives::TableHandle;
use aptos_types::{state_store::state_key::StateKey, vm_status::StatusCode};
use move_binary_format::errors::{PartialVMError, PartialVMResult};
use move_core_types::account_address::AccountAddress;
use std::{collections::{BTreeMap, BTreeSet}, thread::current};

/// Describes the delta of an aggregator.
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum DeltaValue {
    Positive(u128),
    Negative(u128),
}

/// Describes how the `speculative_start_value` in 
/// `AggregatorState` is obtained. 
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum SpeculativeValueSource {
    // The speculative_start_value is assigned to 0.
    Default,
    // The speculative_start_value is obtained by reading
    // the last committed value of the aggregator from MVHashmap.
    LastCommittedValue,
    // The speculative_start_value is obtained by aggregating all
    // the previous deltas of the aggregator from MVHashmap.
    AggregatedValue,
}

/// Describes the state of each aggregator instance.
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum AggregatorState {
    // If aggregator stores a known value.
    Data {value: u128},
    Delta {
        speculative_start_value: u128,
        speculative_source: SpeculativeValueSource,
        delta: DeltaValue,
        history: DeltaHistory
    },
}

#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]
pub struct AggregatorHandle(pub AccountAddress);

/// Uniquely identifies each aggregator instance in storage.
#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]
pub enum AggregatorID {
    // Aggregator V1 is implemented as a Table item, and so can be queried by the
    // state key.
    Legacy {
        // A handle that is shared across all aggregator instances created by the
        // same `AggregatorFactory` and which is used for fine-grained storage
        // access.
        handle: TableHandle,
        // Unique key associated with each aggregator instance. Generated by
        // taking the hash of transaction which creates an aggregator and the
        // number of aggregators that were created by this transaction so far.
        key: AggregatorHandle,
    },
    // Aggregator V2 is implemented in place with ephemeral identifiers which are
    // unique per block.
    Ephemeral(u64),
}

impl AggregatorID {
    pub fn legacy(handle: TableHandle, key: AggregatorHandle) -> Self {
        AggregatorID::Legacy { handle, key }
    }

    pub fn ephemeral(id: u64) -> Self {
        AggregatorID::Ephemeral(id)
    }

    pub fn as_state_key(&self) -> Option<StateKey> {
        match self {
            AggregatorID::Legacy { handle, key } => {
                Some(StateKey::table_item((*handle).into(), key.0.to_vec()))
            },
            AggregatorID::Ephemeral(_) => None,
        }
    }
}

/// Uniquely identifies each aggregator snapshot instance during the block execution.
#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]
pub struct AggregatorSnapshotID {
    pub id: u64,
}

/// Tracks values seen by aggregator. In particular, stores information about
/// the biggest and the smallest deltas seen during execution in the VM. This
/// information can be used by the executor to check if delta should have
/// failed. Most importantly, it allows commutativity of adds/subs. Example:
///
///
/// This graph shows how delta of aggregator changed during a single transaction
/// execution:
///
/// +A ===========================================>
///            ||
///          ||||                               +X
///         |||||  ||||||                    ||||
///      |||||||||||||||||||||||||          |||||
/// +0 ===========================================> time
///                       ||||||
///                         ||
///                         ||
/// -B ===========================================>
///
/// Clearly, +X succeeds if +A and -B succeed. Therefore each delta
/// validation consists of:
///   1. check +A did not overflow
///   2. check -A did not drop below zero
/// Checking +X is irrelevant since +A >= +X.
///
/// TODO: while we support tracking of the history, it is not yet fully used on
/// executor side because we don't know how to throw errors.
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub struct DeltaHistory {
    pub max_achieved_positive_delta: u128,
    pub min_achieved_negative_delta: u128,
    // `min_overflow_positive_delta` is None in two possible cases:
    // 1. No overflow occured in the try_add/try_sub functions throughout the
    // transaction execution.
    // 2. The only overflows that occured in the try_add/try_sub functions in
    // this transaction execution are with delta that exceeds u128::MAX.
    pub min_overflow_positive_delta: Option<u128>,
    // `max_underflow_negative_delta` is None in two possible cases:
    // 1. No underflow occured in the try_add/try_sub functions throughout the
    // transaction execution.
    // 2. The only underflows that occured in the try_add/try_sub functions in
    // this transaction execution are with delta that drops below -u128::MAX.
    pub max_underflow_negative_delta: Option<u128>,
}

impl DeltaHistory {
    fn new() -> Self {
        DeltaHistory {
            max_achieved_positive_delta: 0,
            min_achieved_negative_delta: 0,
            min_overflow_positive_delta: None,
            max_underflow_negative_delta: None,
        }
    }

    /// Records observed delta in history. Should be called after an operation (addition/subtraction)
    /// is successful to record its side-effects.
    fn record_success(&mut self, delta: DeltaValue) {
        match delta {
            DeltaValue::Positive(value) => self.max_achieved_positive_delta = u128::max(self.max_achieved_positive_delta, value),
            DeltaValue::Negative(value) => self.min_achieved_negative_delta = u128::max(self.min_achieved_negative_delta, value),
        }
    }

    /// Records overflows in history. Should be called after an addition is unsuccessful
    /// to record its side-effects.
    fn record_overflow(&mut self, delta: u128) {
        self.min_overflow_positive_delta = self
            .min_overflow_positive_delta
            .map_or(Some(delta), |min| Some(u128::min(min, delta)));
    }

    /// Records underflows in history. Should be called after a subtraction is unsuccessful
    /// to record its side-effects.
    fn record_underflow(&mut self, delta: u128) {
        self.max_underflow_negative_delta = self
            .max_underflow_negative_delta
            .map_or(Some(delta), |min| Some(u128::min(min, delta)));
    }
}

/// Internal AggregatorSnapshot data structure.
#[derive(Debug)]
#[allow(dead_code)]
pub struct AggregatorSnapshot {
    // The identifier used to identify the aggregator snapshot.
    id: AggregatorSnapshotID,
    // Describes an upper bound of an aggregator. If value of the aggregator
    // exceeds it, the aggregator overflows.
    // TODO: Currently this is a single u128 value since we use 0 as a trivial
    // lower bound. If we want to support custom lower bounds, or have more
    // complex postconditions, we should factor this out in its own struct.
    max_value: u128,
    // Describes a state of an aggregator.
    state: AggregatorState,
    // The AggregatorID of the aggregator from which the snapshot is taken.
    base_aggregator: AggregatorID,
}

/// Internal aggregator data structure.
#[derive(Debug)]
pub struct Aggregator {
    // The identifier used to identify the aggregator.
    id: AggregatorID,
    // Describes an upper bound of an aggregator. If value of the aggregator
    // exceeds it, the aggregator overflows.
    // TODO: Currently this is a single u128 value since we use 0 as a trivial
    // lower bound. If we want to support custom lower bounds, or have more
    // complex postconditions, we should factor this out in its own struct.
    max_value: u128,
    // Describes a state of an aggregator.
    state: AggregatorState,
}

impl Aggregator {
    /// Validates if aggregator's history is correct when applied to
    /// the `base_value`. For example, if history observed a delta of
    /// +100, and the aggregator max_value is 150, then the base value of
    /// 60 will not pass validation (60 + 100 > 150), but the base value
    /// of 30 will (30 + 100 < 150).
    fn validate_history(&self, base_value: u128) -> PartialVMResult<()> {
        if let AggregatorState::Delta {speculative_start_value, speculative_source, delta, history} = &self.state {
            // To validate the history of an aggregator, we want to ensure
            // that there was no violation of postcondition (i.e. overflows or
            // underflows). We can do it by emulating addition and subtraction.
            addition(base_value, history.max_achieved_positive_delta, self.max_value)?;
            subtraction(base_value, history.min_achieved_negative_delta)?;
        }
        Ok(())
    }

    fn get_mut_history(&mut self) -> Option<&mut DeltaHistory> {
        if let AggregatorState::Delta {history, ..} = &mut self.state {
            return Some(history);
        }
        None
    }

    /// Implements logic for adding to an aggregator.
    pub fn try_add(&mut self, input: u128) -> PartialVMResult<()> {
        if input > self.max_value {
            // we do not have to record the overflow.
            // We record the delta that result in overflows/underflows so that when we compute the actual value
            // of aggregator, we can figure out if the output of try_add/try_sub changes.
            // When input exceeds max_value, we know that no matter what the starting value of the
            // aggregator is, it always results in an overflow.
            return Err(abort_error(
                format!("overflow occurred as adding a value: {} more than max_value: {}", input, self.max_value),
                EADD_OVERFLOW,
            ));
        }
        match self.state {
            AggregatorState::Data {value} => {
                // If aggregator knows the value, add directly and keep the state.
                self.state = AggregatorState::Data { value: addition(value, input, self.max_value)? };
                return Ok(());
            },
            AggregatorState::Delta {speculative_start_value, speculative_source, delta, history} => {
                let mut new_delta;
                match delta {
                    DeltaValue::Positive(current_delta) => {
                        // If speculative_start_value + delta + input exceeds max_value, it's an overflow.
                        // Otherwise, we update the delta with delta + input.
                        addition(speculative_start_value + current_delta, input, self.max_value).map(|err| {
                            // If current_delta + input exceeds max_value, we do not have to record the overflow.
                            // We record the delta that result in overflows/underflows so that when we compute the actual value
                            // of aggregator, we can figure out if the output of try_add/try_sub changes.
                            // When current_delta + input exceeds max_value, we know that no matter what the starting value of the
                            // aggregator is, it always results in an overflow.
                            if current_delta <= self.max_value - input {
                                self.get_mut_history().unwrap().record_overflow(current_delta + input);
                            }
                            err
                        })?;
                        new_delta = DeltaValue::Positive(addition(current_delta, input, self.max_value).expect("Addition is expected to succeed as the sum <= max_value"));
                    },
                    DeltaValue::Negative(current_delta) => {
                        // If speculative_start_value - current_delta + input is greater than max_value or less than -max_value, it's an overflow.
                        // Otherwise, we update the delta with delta + input.
                        if speculative_start_value + input < current_delta {
                            // speculative_start_value - current_delta + input < 0
                            new_delta = DeltaValue::Negative(subtraction(current_delta, input).expect("Subtraction of smaller value from larger value must succeed"));
                        } else {
                            // speculative_start_value - current_delta + input > 0
                            if  speculative_start_value + input - current_delta > self.max_value {
                                self.get_mut_history().unwrap().record_overflow(input - current_delta);
                                return Err(abort_error(
                                    format!("overflow occurred when adding {} to speculative_start_value: {}, current_delta: -{}", input, speculative_start_value, current_delta),
                                    EADD_OVERFLOW,
                                ));
                            }
                            new_delta = if input > current_delta {
                                DeltaValue::Positive(subtraction(input, current_delta).expect("Subtraction of smaller value from larger value must succeed"))
                            } else {
                                DeltaValue::Negative(subtraction(current_delta, input).expect("Subtraction of smaller value from larger value must succeed"))
                            };
                        }
                    }
                }
                self.state = AggregatorState::Delta {
                    speculative_start_value,
                    speculative_source,
                    delta: new_delta,
                    history,
                };
                self.get_mut_history().unwrap().record_success(new_delta);
            }
        }
        Ok(())
    }

    /// Implements logic for subtracting from an aggregator.
    pub fn try_sub(&mut self, input: u128) -> PartialVMResult<()> {
        if input > self.max_value {
            // we do not have to record the underflow.
            // We record the delta that result in overflows/underflows so that when we compute the actual value
            // of aggregator, we can figure out if the output of try_add/try_sub changes.
            // When input exceeds max_value, we know that no matter what the starting value of the
            // aggregator is, it always results in an underflow.
            return Err(abort_error(
                format!("underflow occurred as subtracting input {} more than max_value: {}", input, self.max_value),
                ESUB_UNDERFLOW,
            ));
        }
        match self.state {
            AggregatorState::Data {value} => {
                // If aggregator knows the value, add directly and keep the state.
                self.state = AggregatorState::Data { value: subtraction(value, input)? };
                return Ok(());
            },
            AggregatorState::Delta { speculative_start_value, speculative_source, delta, history } => {
                let mut new_delta;
                match delta {
                    DeltaValue::Positive(current_delta) => {
                        // If speculative_start_value + current_delta - input is less than 0, it's an underflow.
                        // Otherwise, we update the delta with delta - input.
                        if speculative_start_value + current_delta < input {
                            self.get_mut_history().unwrap().record_underflow(input - current_delta);
                            return Err(abort_error(
                                format!("underflow occurred when subtracting {} from speculative_start_value: {}, current_delta: {}", input, speculative_start_value, current_delta),
                                ESUB_UNDERFLOW,
                            ));
                        }
                        new_delta = if current_delta >= input {
                            DeltaValue::Positive(subtraction(current_delta, input).expect("Subtraction of smaller value from larger value must succeed"))
                        } else {
                            DeltaValue::Negative(subtraction(input, current_delta).expect("Subtraction of smaller value from larger value must succeed"))
                        };
                    }
                    DeltaValue::Negative(current_delta) => {
                        // If speculative_start_value - current_delta - input is less than 0, it's an underflow.
                        // Otherwise, we update the delta with delta - input.
                        if speculative_start_value > current_delta + input {
                            self.get_mut_history().unwrap().record_underflow(input + current_delta);
                            return Err(abort_error(
                                format!("underflow occurred when subtracting {} from speculative_start_value: {}, current_delta: -{}", input, speculative_start_value, current_delta),
                                EADD_OVERFLOW,
                            ));
                        }
                        new_delta = DeltaValue::Negative(addition(current_delta, input, self.max_value).expect("Adding two values must succeed as the sum <= max_value"));
                    }
                }
                self.state = AggregatorState::Delta {
                    speculative_start_value,
                    speculative_source,
                    delta: new_delta,
                    history,
                };
                self.get_mut_history().unwrap().record_success(new_delta);
            }
        }
        Ok(())
    }


    /// Implements logic for doing a "cheap read" of an aggregator.
    /// This means that we query the MVHashmap for the last committed value
    /// of the aggregator, and store it in the `speculative_start_value`, with
    /// `speculative_source` as `LastCommitted`.
    pub fn read_last_committed_aggregator_value(
        &mut self,
        resolver: &dyn AggregatorResolver,
        id: &AggregatorID,
    ) -> PartialVMResult<u128> {
        match self.state {
            AggregatorState::Data { value } => {
                // If aggregator knows the value, return it.
                return Ok(value);
            },
            AggregatorState::Delta { speculative_start_value, speculative_source, delta, history } => {
                // If we performed a "cheap read" or "expensive read" operation before, use it.
                if speculative_source == SpeculativeValueSource::Default {
                    return match delta {
                        DeltaValue::Positive(value) => Ok(addition(speculative_start_value, value, self.max_value)?),
                        DeltaValue::Negative(value) => Ok(subtraction(speculative_start_value, value)?),
                    };
                }
                // Otherwise, we have to go to storage and read the value.
                let value_from_storage = resolver.resolve_aggregator_value(id).map_err(|e| {
                    extension_error(format!("Could not find the value of the aggregator: {}", e))
                })?;
        
                // Validate history and apply the delta.
                self.validate_history(value_from_storage)?;
                self.state = AggregatorState::Delta {
                    speculative_start_value: value_from_storage,
                    speculative_source: SpeculativeValueSource::LastCommittedValue,
                    delta,
                    history,
                };
                return match delta {
                    DeltaValue::Positive(value) => Ok(addition(value_from_storage, value, self.max_value)?),
                    DeltaValue::Negative(value) => Ok(subtraction(value_from_storage, value)?),
                };
            }
        }
    }
    
    /// Implements logic for reading the value of an aggregator. As a
    /// result, the aggregator knows it value (i.e. its state changes to
    /// `Data`).
    pub fn read_and_materialize(
        &mut self,
        resolver: &dyn AggregatorResolver,
        id: &AggregatorID,
    ) -> PartialVMResult<u128> {
        // If aggregator has already been read, return immediately.
        if let AggregatorState::Data {value} = self.state {
            return Ok(value);
        }
        // Otherwise, we have a delta and have to go to storage and apply it.
        // In theory, any delta will be applied to existing value. However,
        // something may go wrong, so we guard by throwing an error in
        // extension.
        let value_from_storage = resolver.resolve_aggregator_value(id).map_err(|e| {
            extension_error(format!("Could not find the value of the aggregator: {}", e))
        })?;

        // Validate history and apply the delta.
        self.validate_history(value_from_storage)?;
        match self.state {
            AggregatorState::PositiveDelta => {
                self.value = addition(value_from_storage, self.value, self.max_value)?;
            },
            AggregatorState::NegativeDelta => {
                self.value = subtraction(value_from_storage, self.value)?;
            },
            AggregatorState::Data => {
                unreachable!("Materialization only happens in Delta state")
            },
        }

        // Change the state and return the new value. Also, make
        // sure history is no longer tracked.
        self.state = AggregatorState::Data;
        self.history = None;
        Ok(self.value)
    }

    /// Unpacks aggregator into its fields.
    pub fn into(self) -> (u128, AggregatorState, u128, Option<DeltaHistory>) {
        (self.value, self.state, self.max_value, self.history)
    }
}

/// Stores all information about aggregators (how many have been created or
/// removed), what are their states, etc. per single transaction).
#[derive(Default)]
pub struct AggregatorData {
    // All aggregators that were created in the current transaction, stored as ids.
    // Used to filter out aggregators that were created and destroyed in the
    // within a single transaction.
    new_aggregators: BTreeSet<AggregatorID>,
    // All aggregators that were destroyed in the current transaction, stored as ids.
    destroyed_aggregators: BTreeSet<AggregatorID>,
    // All aggregator instances that exist in the current transaction.
    aggregators: BTreeMap<AggregatorID, Aggregator>,
    // All aggregatorsnapshot instances that exist in the current transaction.
    aggregator_snapshots: BTreeMap<AggregatorSnapshotID, AggregatorSnapshot>,
    // Counter for generating identifiers for AggregatorSnapshots.
    pub id_counter: u64,
}

impl AggregatorData {
    pub fn new(id_counter: u64) -> Self {
        Self {
            id_counter,
            ..Default::default()
        }
    }

    /// Returns a mutable reference to an aggregator with `id` and a `max_value`.
    /// If transaction that is currently executing did not initialize it, a new aggregator instance is created.
    /// Note: when we say "aggregator instance" here we refer to Rust struct and
    /// not to the Move aggregator.
    pub fn get_aggregator(
        &mut self,
        id: AggregatorID,
        max_value: u128,
    ) -> PartialVMResult<&mut Aggregator> {
        let aggregator = self.aggregators.entry(id).or_insert(Aggregator {
            id,
            state: AggregatorState::Delta {
                speculative_start_value: 0,
                speculative_source: SpeculativeValueSource::LastCommittedValue,
                delta: DeltaValue::Positive(0),
                history: DeltaHistory::new(),
            },
            max_value,
        });
        Ok(aggregator)
    }

    /// Returns the number of aggregators that are used in the current transaction.
    pub fn num_aggregators(&self) -> u128 {
        self.aggregators.len() as u128
    }

    /// Creates and a new Aggregator with a given `id` and a `max_value`. The value
    /// of a new aggregator is always known, therefore it is created in a data
    /// state, with a zero-initialized value.
    pub fn create_new_aggregator(&mut self, id: AggregatorID, max_value: u128) {
        let aggregator = Aggregator {
            id,
            state: AggregatorState::Data {value: 0},
            max_value,
        };
        self.aggregators.insert(id, aggregator);
        self.new_aggregators.insert(id);
    }

    /// If aggregator has been used in this transaction, it is removed. Otherwise,
    /// it is marked for deletion.
    pub fn remove_aggregator(&mut self, id: AggregatorID) {
        // Aggregator no longer in use during this transaction: remove it.
        self.aggregators.remove(&id);

        if self.new_aggregators.contains(&id) {
            // Aggregator has been created in the same transaction. Therefore, no
            // side-effects.
            self.new_aggregators.remove(&id);
        } else {
            // Otherwise, aggregator has been created somewhere else.
            self.destroyed_aggregators.insert(id);
        }
    }

    pub fn snapshot(&mut self, id: &AggregatorID) -> AggregatorSnapshotID {
        let snapshot_id = AggregatorSnapshotID {
            id: self.generate_id(),
        };
        let aggregator = self.aggregators.get(id).expect("Aggregator doesn't exist");
        self.aggregator_snapshots
            .insert(snapshot_id, AggregatorSnapshot {
                id: snapshot_id,
                state: aggregator.state,
                max_value: aggregator.max_value,
                base_aggregator: *id,
            });
        snapshot_id
    }

    pub fn read_snapshot(&self, id: AggregatorSnapshotID) -> u128 {
        let snapshot = self
            .aggregator_snapshots
            .get(&id)
            .expect("AggregatorSnapshot doesn't exist");
        snapshot.value
    }

    pub fn generate_id(&mut self) -> u64 {
        self.id_counter += 1;
        self.id_counter
    }

    /// Unpacks aggregator data.
    pub fn into(
        self,
    ) -> (
        BTreeSet<AggregatorID>,
        BTreeSet<AggregatorID>,
        BTreeMap<AggregatorID, Aggregator>,
    ) {
        (
            self.new_aggregators,
            self.destroyed_aggregators,
            self.aggregators,
        )
    }
}

/// Returns partial VM error on extension failure.
pub fn extension_error(message: impl ToString) -> PartialVMError {
    PartialVMError::new(StatusCode::VM_EXTENSION_ERROR).with_message(message.to_string())
}

// ================================= Tests =================================

#[cfg(test)]
mod test {
    use super::*;
    use crate::{aggregator_id_for_test, AggregatorStore};
    use claims::{assert_err, assert_ok};
    use once_cell::sync::Lazy;

    #[allow(clippy::redundant_closure)]
    static TEST_RESOLVER: Lazy<AggregatorStore> = Lazy::new(|| AggregatorStore::default());

    #[test]
    fn test_materialize_not_in_storage() {
        let mut aggregator_data = AggregatorData::default();

        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(300), 700)
            .expect("Get aggregator failed");
        assert_err!(aggregator.read_and_materialize(&*TEST_RESOLVER, &aggregator_id_for_test(700)));
    }

    #[test]
    fn test_materialize_known() {
        let mut aggregator_data = AggregatorData::default();
        aggregator_data.create_new_aggregator(aggregator_id_for_test(200), 200);

        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(200), 200)
            .expect("Get aggregator failed");
        assert_ok!(aggregator.try_add(100));
        assert_ok!(aggregator.read_and_materialize(&*TEST_RESOLVER, &aggregator_id_for_test(200)));
        assert_eq!(aggregator.value, 100);
    }

    #[test]
    fn test_materialize_overflow() {
        let mut aggregator_data = AggregatorData::default();

        // +0 to +400 satisfies <= 600 and is ok, but materialization fails
        // with 300 + 400 > 600!
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(600), 600)
            .expect("Get aggregator failed");
        assert_ok!(aggregator.try_add(400));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            400
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            None
        );
        assert_err!(aggregator.read_and_materialize(&*TEST_RESOLVER, &aggregator_id_for_test(600)));
    }

    #[test]
    fn test_materialize_underflow() {
        let mut aggregator_data = AggregatorData::default();

        // +0 to -400 is ok, but materialization fails with 300 - 400 < 0!
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(600), 600)
            .expect("Get aggregator failed");
        assert_ok!(aggregator.try_sub(400));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            400
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            None
        );
        assert_err!(aggregator.read_and_materialize(&*TEST_RESOLVER, &aggregator_id_for_test(600)));
    }

    #[test]
    fn test_materialize_non_monotonic_1() {
        let mut aggregator_data = AggregatorData::default();

        // +0 to +400 to +0 is ok, but materialization fails since we had 300 + 400 > 600!
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(600), 600)
            .expect("Get aggregator failed");
        assert_ok!(aggregator.try_add(400));
        assert_ok!(aggregator.try_sub(300));
        assert_eq!(aggregator.value, 100);
        assert_eq!(aggregator.state, AggregatorState::PositiveDelta);
        assert_err!(aggregator.read_and_materialize(&*TEST_RESOLVER, &aggregator_id_for_test(600)));
    }

    #[test]
    fn test_materialize_non_monotonic_2() {
        let mut aggregator_data = AggregatorData::default();

        // +0 to -301 to -300 is ok, but materialization fails since we had 300 - 301 < 0!
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(600), 600)
            .expect("Get aggregator failed");
        assert_ok!(aggregator.try_sub(301));
        assert_ok!(aggregator.try_add(1));
        assert_eq!(aggregator.value, 300);
        assert_eq!(aggregator.state, AggregatorState::NegativeDelta);
        assert_err!(aggregator.read_and_materialize(&*TEST_RESOLVER, &aggregator_id_for_test(600)));
    }

    #[test]
    fn test_add_overflow() {
        let mut aggregator_data = AggregatorData::default();

        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(600), 600)
            .expect("Get aggregator failed");

        // +0 to +800 > 600!
        assert_err!(aggregator.try_add(800));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            0
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            Some(800)
        );

        // +0 + 300 < 600
        assert_ok!(aggregator.try_add(300));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            300
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            Some(800)
        );

        // +300 + 400 > 600!
        assert_err!(aggregator.try_add(400));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            300
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            Some(700)
        );

        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(200), 200)
            .expect("Get aggregator failed");

        // 0 + 100 < 200
        assert_ok!(aggregator.try_add(100));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            None
        );

        // 100 + 200 > 200!
        assert_err!(aggregator.try_add(200));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            Some(300)
        );

        // 100 + 150 > 200!
        assert_err!(aggregator.try_add(150));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            Some(250)
        );

        // 100 + u128::MAX > 200!
        assert_err!(aggregator.try_add(u128::MAX));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            Some(250)
        );

        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(300), 300)
            .expect("Get aggregator failed");

        // 0 + 100 < 300!
        assert_ok!(aggregator.try_add(100));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            None
        );

        // 100 + u128::MAX > 300!
        assert_err!(aggregator.try_add(u128::MAX));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            None
        );

        // 100 + 250 > 300!
        assert_err!(aggregator.try_add(250));
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_overflow_positive,
            Some(350)
        );
    }

    #[test]
    fn test_sub_underflow() {
        let mut aggregator_data = AggregatorData::default();
        aggregator_data.create_new_aggregator(aggregator_id_for_test(200), 200);

        // +0 to -601 is impossible!
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(600), 600)
            .expect("Get aggregator failed");
        assert_err!(aggregator.try_sub(700));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            0
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            Some(700)
        );

        assert_ok!(aggregator.try_add(200));

        assert_ok!(aggregator.try_sub(300));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            Some(700)
        );

        assert_err!(aggregator.try_sub(550));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            Some(650)
        );

        assert_err!(aggregator.try_sub(800));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            Some(650)
        );

        // Similarly, we cannot subtract anything from 0...
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(200), 200)
            .expect("Get aggregator failed");

        assert_err!(aggregator.try_sub(2));

        // Similarly, we cannot subtract anything from 0...
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(300), 300)
            .expect("Get aggregator failed");

        assert_ok!(aggregator.try_sub(100));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );

        assert_err!(aggregator.try_sub(u128::MAX));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            None
        );

        assert_ok!(aggregator.try_sub(100));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            200
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            None
        );

        assert_err!(aggregator.try_sub(101));
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            200
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_underflow_negative,
            Some(301)
        );
    }

    #[test]
    fn test_commutative() {
        let mut aggregator_data = AggregatorData::default();

        // +200 -300 +50 +300 -25 +375 -600.
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(600), 600)
            .expect("Get aggregator failed");
        assert_ok!(aggregator.try_add(200));
        assert_ok!(aggregator.try_sub(300));

        assert_eq!(aggregator.value, 100);
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            200
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );
        assert_eq!(aggregator.state, AggregatorState::NegativeDelta);

        assert_ok!(aggregator.try_add(50));
        assert_ok!(aggregator.try_add(300));
        assert_ok!(aggregator.try_sub(25));

        assert_eq!(aggregator.value, 225);
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            250
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );
        assert_eq!(aggregator.state, AggregatorState::PositiveDelta);

        assert_ok!(aggregator.try_add(375));
        assert_ok!(aggregator.try_sub(600));

        assert_eq!(aggregator.value, 0);
        assert_eq!(
            aggregator.history.as_ref().unwrap().max_achieved_positive,
            600
        );
        assert_eq!(
            aggregator.history.as_ref().unwrap().min_achieved_negative,
            100
        );
        assert_eq!(aggregator.state, AggregatorState::PositiveDelta);
    }

    #[test]
    #[should_panic]
    fn test_history_validation_in_data_state() {
        let mut aggregator_data = AggregatorData::default();

        // Validation panics if history is not set. This is an invariant
        // violation and should never happen.
        aggregator_data.create_new_aggregator(aggregator_id_for_test(200), 200);
        let aggregator = aggregator_data
            .get_aggregator(aggregator_id_for_test(200), 200)
            .expect("Getting an aggregator should succeed");
        aggregator
            .validate_history(0)
            .expect("Should not be called because validation panics");
    }

    #[test]
    fn test_history_validation_in_delta_state() {
        let mut aggregator_data = AggregatorData::default();

        // Some aggregator with a max_value of 100 in a delta state.
        let id = aggregator_id_for_test(100);
        let aggregator = aggregator_data
            .get_aggregator(id, 100)
            .expect("Getting an aggregator should succeed");

        // Aggregator of +0 with minimum of -50 and maximum of +50.
        aggregator.try_add(50).unwrap();
        aggregator.try_sub(100).unwrap();
        aggregator.try_add(50).unwrap();

        // Valid history: 50+50-100+50.
        assert_ok!(aggregator.validate_history(50));

        // Underflow and overflow are unvalidated.
        assert_err!(aggregator.validate_history(49));
        assert_err!(aggregator.validate_history(51));
    }
}
